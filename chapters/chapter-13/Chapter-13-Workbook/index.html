
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A comprehensive guide to the foundations of quantum computing">
      
      
        <meta name="author" content="Big Book of Computing">
      
      
        <link rel="canonical" href="https://bigbookofcomputing.github.io/chapters/chapter-13/Chapter-13-Workbook/">
      
      
        <link rel="prev" href="../../chapter-12/Chapter-12-Workbook/">
      
      
        <link rel="next" href="../../chapter-14/Chapter-14-Workbook/">
      
      
        
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Chapter-13 Quantum Reinforcement Learning - Big Book of Computing | Quantum Computing</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    
      <link rel="stylesheet" href="../../../static/styles.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-ECS7B3X8JM"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-ECS7B3X8JM",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-ECS7B3X8JM",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script>
  

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-13-quantum-reinforcement-learning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Big Book of Computing | Quantum Computing" class="md-header__button md-logo" aria-label="Big Book of Computing | Quantum Computing" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Big Book of Computing | Quantum Computing
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Chapter-13 Quantum Reinforcement Learning
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/bigbookofcomputing/quantum" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../contents/" class="md-tabs__link">
        
  
  
    
  
  Contents

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../introduction/" class="md-tabs__link">
        
  
  
    
  
  Introduction

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter-1/Chapter-1-Essay/" class="md-tabs__link">
          
  
  
    
  
  Chapters

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../chapter-1/Chapter-1-Workbook/" class="md-tabs__link">
          
  
  
    
  
  WorkBooks

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter-1/Chapter-1-Codebook/" class="md-tabs__link">
          
  
  
    
  
  CodeBooks

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Big Book of Computing | Quantum Computing" class="md-nav__button md-logo" aria-label="Big Book of Computing | Quantum Computing" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    Big Book of Computing | Quantum Computing
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/bigbookofcomputing/quantum" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contents
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Chapters
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Chapters
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-1/Chapter-1-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-1 Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-2/Chapter-2-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-2 State and Operators
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-3/Chapter-3-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-3 Gate and Circuits
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-4/Chapter-4-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-4 Quantum Algorithms
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-5/Chapter-5-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-5 Quantum Fourier Transform
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-6/Chapter-6-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-6 Variational Algorithms
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-7/Chapter-7-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-7 Quantum Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-8/Chapter-8-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-8 Quantum Machine Learning and Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-9/Chapter-9-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-9 Encoding Classical Data into Quantum States
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-10/Chapter-10-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-10 Variational Quantum Classifiers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-11/Chapter-11-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-11 Supervised Quantum Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-12/Chapter-12-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-12 Unsupervised Quantum Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter-13-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-13 Quantum Reinforcement Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-14/Chapter-14-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-14 QUBO Family of Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-15/Chapter-15-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-15 Quantum Data Pipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-16/Chapter-16-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-16 Quantum Simulation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-17/Chapter-17-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-17 Quantum Chemistry
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-18/Chapter-18-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-18 Quantum Finance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-19/Chapter-19-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-19 Quantum Hardware
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-20/Chapter-20-Essay/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-20 Quantum Error Correction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    WorkBooks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    WorkBooks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-1/Chapter-1-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-1 Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-2/Chapter-2-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-2 State and Operators
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-3/Chapter-3-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-3 Gate and Circuits
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-4/Chapter-4-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-4 Quantum Algorithms
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-5/Chapter-5-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-5 Quantum Fourier Transform
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-6/Chapter-6-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-6 Variational Algorithms
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-7/Chapter-7-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-7 Quantum Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-8/Chapter-8-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-8 Quantum Machine Learning and Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-9/Chapter-9-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-9 Encoding Classical Data into Quantum States
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-10/Chapter-10-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-10 Variational Quantum Classifiers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-11/Chapter-11-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-11 Supervised Quantum Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-12/Chapter-12-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-12 Unsupervised Quantum Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Chapter-13 Quantum Reinforcement Learning
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-13 Quantum Reinforcement Learning
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#131-the-reinforcement-learning-framework" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.1 The Reinforcement Learning Framework
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.1 The Reinforcement Learning Framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#132-quantum-policy-gradient-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.2 Quantum Policy Gradient Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.2 Quantum Policy Gradient Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hands-on-projects" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hands-On Projects
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Hands-On Projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#project-blueprint-policy-gradient-update-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Project Blueprint: Policy Gradient Update Calculation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pseudocode-for-the-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pseudocode for the Calculation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#outcome-and-interpretation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Outcome and Interpretation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#133-quantum-value-iteration" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3 Quantum Value Iteration
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.3 Quantum Value Iteration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hands-on-projects_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hands-On Projects
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Hands-On Projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#project-blueprint-value-iteration-loss-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Project Blueprint: Value Iteration Loss Calculation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pseudocode-for-the-calculation_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pseudocode for the Calculation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#outcome-and-interpretation_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Outcome and Interpretation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#134-quantum-exploration-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4 Quantum Exploration Strategies
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.4 Quantum Exploration Strategies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#135-quantum-agent-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.5 Quantum Agent Architectures
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.5 Quantum Agent Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-14/Chapter-14-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-14 QUBO Family of Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-15/Chapter-15-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-15 Quantum Data Pipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-16/Chapter-16-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-16 Quantum Simulation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-17/Chapter-17-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-17 Quantum Chemistry
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-18/Chapter-18-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-18 Quantum Finance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-19/Chapter-19-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-19 Quantum Hardware
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-20/Chapter-20-Workbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-20 Quantum Error Correction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    CodeBooks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    CodeBooks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-1/Chapter-1-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-1 Introduction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-2/Chapter-2-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-2 State and Operators
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-3/Chapter-3-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-3 Gate and Circuits
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-4/Chapter-4-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-4 Quantum Algorithms
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-5/Chapter-5-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-5 Quantum Fourier Transform
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-6/Chapter-6-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-6 Variational Algorithms
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-7/Chapter-7-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-7 Quantum Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-8/Chapter-8-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-8 Quantum Machine Learning and Optimization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-9/Chapter-9-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-9 Encoding Classical Data into Quantum States
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-10/Chapter-10-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-10 Variational Quantum Classifiers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-11/Chapter-11-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-11 Supervised Quantum Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-12/Chapter-12-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-12 Unsupervised Quantum Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Chapter-13-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-13 Quantum Reinforcement Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-14/Chapter-14-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-14 QUBO Family of Problems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-15/Chapter-15-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-15 Quantum Data Pipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-16/Chapter-16-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-16 Quantum Simulation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-17/Chapter-17-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-17 Quantum Chemistry
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-18/Chapter-18-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-18 Quantum Finance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-19/Chapter-19-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-19 Quantum Hardware
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter-20/Chapter-20-Codebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chapter-20 Quantum Error Correction
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#131-the-reinforcement-learning-framework" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.1 The Reinforcement Learning Framework
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.1 The Reinforcement Learning Framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#132-quantum-policy-gradient-methods" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.2 Quantum Policy Gradient Methods
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.2 Quantum Policy Gradient Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hands-on-projects" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hands-On Projects
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Hands-On Projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#project-blueprint-policy-gradient-update-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Project Blueprint: Policy Gradient Update Calculation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pseudocode-for-the-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pseudocode for the Calculation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#outcome-and-interpretation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Outcome and Interpretation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#133-quantum-value-iteration" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.3 Quantum Value Iteration
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.3 Quantum Value Iteration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hands-on-projects_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Hands-On Projects
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Hands-On Projects">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#project-blueprint-value-iteration-loss-calculation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Project Blueprint: Value Iteration Loss Calculation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pseudocode-for-the-calculation_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pseudocode for the Calculation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#outcome-and-interpretation_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Outcome and Interpretation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#134-quantum-exploration-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.4 Quantum Exploration Strategies
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.4 Quantum Exploration Strategies">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#135-quantum-agent-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      
        13.5 Quantum Agent Architectures
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="13.5 Quantum Agent Architectures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#theoretical-background_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Theoretical Background
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehension-check_4" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehension Check
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/bigbookofcomputing/quantum/edit/master/docs/chapters/chapter-13/Chapter-13-Workbook.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/bigbookofcomputing/quantum/raw/master/docs/chapters/chapter-13/Chapter-13-Workbook.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="chapter-13-quantum-reinforcement-learning"><strong>Chapter 13: Quantum Reinforcement Learning</strong></h1>
<hr />
<blockquote>
<p><strong>Summary:</strong> This chapter introduces Quantum Reinforcement Learning (QRL), a hybrid field that integrates quantum computing with classical reinforcement learning to tackle exponentially complex environments. We explore how QRL leverages Parameterized Quantum Circuits (PQCs) to represent policies and value functions, potentially offering richer function approximation due to the vastness of quantum Hilbert space. The chapter examines core QRL paradigms, including quantum policy gradient methods and quantum value iteration, and discusses novel exploration strategies like quantum random walks. This provides a foundation for understanding how quantum computation may enhance an agent's ability to learn optimal strategies in high-dimensional problem spaces.</p>
</blockquote>
<hr />
<p>The goal of this chapter is to establish the foundational concepts and techniques of Quantum Reinforcement Learning (QRL), exploring how quantum computing can enhance traditional reinforcement learning frameworks.</p>
<hr />
<h2 class="heading-with-pill" id="131-the-reinforcement-learning-framework"><strong>13.1 The Reinforcement Learning Framework</strong></h2>
<blockquote>
<p><strong>Difficulty:</strong> </p>
<p><strong>Concept:</strong> Agent-Environment Interaction Loop</p>
<p><strong>Summary:</strong> Reinforcement Learning (RL) models an agent that learns to make optimal decisions by interacting with an environment. The agent's goal is to maximize its cumulative reward over time by learning a policy that maps states to actions. QRL adapts this by representing components like the policy or value function with quantum circuits.</p>
</blockquote>
<hr />
<h3 id="theoretical-background"><strong>Theoretical Background</strong></h3>
<p>The foundation of Reinforcement Learning (RL) is the <strong>agent-environment loop</strong>. An <strong>agent</strong> exists in a certain <strong>state</strong> (<span class="arithmatex">\(s_t\)</span>) within an <strong>environment</strong>. It takes an <strong>action</strong> (<span class="arithmatex">\(a_t\)</span>), and in response, the environment transitions to a new state (<span class="arithmatex">\(s_{t+1}\)</span>) and provides the agent with a scalar <strong>reward</strong> (<span class="arithmatex">\(r_{t+1}\)</span>).</p>
<p>The agent's objective is to learn a <strong>policy</strong>, denoted <span class="arithmatex">\(\pi(a|s)\)</span>, which is a strategy that dictates the probability of taking action <span class="arithmatex">\(a\)</span> while in state <span class="arithmatex">\(s\)</span>. A good policy is one that maximizes the <strong>expected return</strong>, <span class="arithmatex">\(G_t\)</span>, which is the sum of all future rewards, usually discounted by a factor <span class="arithmatex">\(\gamma \in [0, 1)\)</span>:</p>
<div class="arithmatex">\[
G_t = \sum_{k=0}^{\infty} \gamma^k r_{t+k+1}
\]</div>
<p>The discount factor <span class="arithmatex">\(\gamma\)</span> prioritizes immediate rewards over distant ones.</p>
<p><strong>Quantum Reinforcement Learning (QRL)</strong> integrates quantum computing into this framework. Instead of using classical models like neural networks to represent the policy or value functions, QRL employs <strong>Parameterized Quantum Circuits (PQCs)</strong>. This offers the potential to explore more complex representations and strategies by leveraging high-dimensional Hilbert spaces and quantum phenomena like superposition and entanglement.</p>
<hr />
<h3 id="comprehension-check"><strong>Comprehension Check</strong></h3>
<div class="admonition note">
<p class="admonition-title">Quiz</p>
<ol>
<li>In the classical RL setup, which quantity is the agent's primary goal to maximize?</li>
<li>In QRL, what quantum computational structure is typically used to approximate the policy or value functions?</li>
</ol>
<details class="info">
<summary>See Answer</summary>
<ol>
<li>The <strong>expected return <span class="arithmatex">\(G_t\)</span></strong> (cumulative discounted rewards).</li>
<li>A <strong>Parameterized Quantum Circuit (PQC)</strong> or a related quantum model.</li>
</ol>
</details>
</div>
<div class="admonition abstract">
<p class="admonition-title">Interview-Style Question</p>
<p>A client asks why you would use a PQC to model an RL policy instead of a standard neural network. What is the core theoretical advantage you would cite?</p>
<details class="info" open="open">
<summary>Answer Strategy</summary>
<p>The core theoretical advantage is the potentially superior <strong>expressive power</strong> of a Parameterized Quantum Circuit (PQC).</p>
<ol>
<li><strong>Access to a Larger State Space:</strong> A PQC operates in an exponentially large Hilbert space. This allows it to represent far more complex functions and strategies than a classical neural network of a comparable size.</li>
<li><strong>Modeling Complex Correlations:</strong> By leveraging quantum entanglement, a PQC can naturally capture intricate, non-local correlations within the environment's state space. A classical network might require a much larger and deeper architecture to model these same relationships, if it can at all.</li>
</ol>
<p>In essence, you are giving the agent a more powerful "brain" to find more sophisticated and effective policies, especially in environments with complex, quantum-like structures.</p>
</details>
</div>
<hr />
<h2 class="heading-with-pill" id="132-quantum-policy-gradient-methods"><strong>13.2 Quantum Policy Gradient Methods</strong></h2>
<blockquote>
<p><strong>Difficulty:</strong> </p>
<p><strong>Concept:</strong> Direct Policy Optimization with PQCs</p>
<p><strong>Summary:</strong> Quantum policy gradient algorithms directly optimize the parameters of a quantum policy to maximize expected rewards. They use a PQC to represent the policy and leverage quantum properties like superposition to enhance state space exploration, while a classical optimizer performs the parameter updates.</p>
</blockquote>
<hr />
<h3 id="theoretical-background_1"><strong>Theoretical Background</strong></h3>
<p>Policy gradient methods are a class of RL algorithms that directly learn the parameters <span class="arithmatex">\(\theta\)</span> of a policy <span class="arithmatex">\(\pi_\theta(a|s)\)</span>. The goal is to adjust <span class="arithmatex">\(\theta\)</span> in the direction that increases the expected return. This is achieved using gradient ascent on an objective function <span class="arithmatex">\(J(\theta)\)</span>.</p>
<p>The <strong>policy gradient theorem</strong> provides a way to compute this gradient:</p>
<div class="arithmatex">\[
\nabla_\theta J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \nabla_\theta \log \pi_\theta(a_t|s_t) \cdot G_t \right]
\]</div>
<p>In <strong>Quantum Policy Gradient</strong> methods, the policy <span class="arithmatex">\(\pi_\theta(a|s)\)</span> is implemented with a PQC. The state <span class="arithmatex">\(s\)</span> is encoded into the circuit, which is parameterized by <span class="arithmatex">\(\theta\)</span>. An action <span class="arithmatex">\(a\)</span> is then sampled by measuring the output qubits.</p>
<p>The term <span class="arithmatex">\(\nabla_\theta \log \pi_\theta(a|s)\)</span> is the <strong>score function</strong>. It indicates how to change <span class="arithmatex">\(\theta\)</span> to increase the probability of taking action <span class="arithmatex">\(a\)</span> from state <span class="arithmatex">\(s\)</span>. Multiplying this by the return <span class="arithmatex">\(G_t\)</span> means we "reinforce" actions that lead to high rewards. If <span class="arithmatex">\(G_t\)</span> is positive and large, we strongly push <span class="arithmatex">\(\theta\)</span> in the direction that makes action <span class="arithmatex">\(a_t\)</span> more likely. If <span class="arithmatex">\(G_t\)</span> is negative, we push <span class="arithmatex">\(\theta\)</span> in the opposite direction.</p>
<p>A key potential advantage of the quantum approach is <strong>enhanced exploration</strong>. By preparing the input state in a superposition, the agent can, in a sense, evaluate the policy for multiple states simultaneously, allowing for a more efficient search of the state-action space.</p>
<hr />
<h3 id="comprehension-check_1"><strong>Comprehension Check</strong></h3>
<div class="admonition note">
<p class="admonition-title">Quiz</p>
<ol>
<li>What is the role of the term <span class="arithmatex">\(\nabla_\theta \log \pi_\theta(a|s)\)</span> in the policy gradient update rule?</li>
<li>In the quantum formulation, what quantum property is often cited as a way to enhance the search process?</li>
</ol>
<details class="info">
<summary>See Answer</summary>
<ol>
<li>It is the <strong>score function</strong>, which acts as a directional indicator. It tells the optimizer how to change the parameters <span class="arithmatex">\(\theta\)</span> to make the chosen action more (or less) likely.</li>
<li><strong>Superposition</strong>, which can be used for more effective and potentially parallel exploration of the state space.</li>
</ol>
</details>
</div>
<div class="admonition abstract">
<p class="admonition-title">Interview-Style Question</p>
<p>Explain the intuition behind the policy gradient update rule <span class="arithmatex">\(\nabla_\theta J(\theta) \propto \nabla_\theta \log \pi_\theta(a|s) \cdot G_t\)</span>. Why the logarithm?</p>
<details class="info" open="open">
<summary>Answer Strategy</summary>
<p>The intuition is simple: <strong>"If an action led to a good outcome, make it more likely. If it led to a bad outcome, make it less likely."</strong></p>
<ol>
<li><strong>The Outcome Signal (<span class="arithmatex">\(G_t\)</span>):</strong> The return, <span class="arithmatex">\(G_t\)</span>, is the "goodness" signal. A large positive <span class="arithmatex">\(G_t\)</span> means the action was beneficial, while a negative <span class="arithmatex">\(G_t\)</span> means it was detrimental.</li>
<li><strong>The Directional Pointer (<span class="arithmatex">\(\nabla_\theta \log \pi_\theta(a|s)\)</span>):</strong> This term, the score function, tells us which way to adjust the parameters <span class="arithmatex">\(\theta\)</span> to increase the probability of the specific action we just took.</li>
<li><strong>Why the Logarithm?</strong> The logarithm is a mathematical tool (the "log-derivative trick") that makes the gradient calculable. It converts the gradient of the policy into a form that can be estimated by sampling. Without it, calculating the gradient would require knowing the full, often intractable, dynamics of the environment. It allows us to estimate the gradient using only the agent's own experience.</li>
</ol>
</details>
</div>
<hr />
<h3 id="hands-on-projects"><strong><i class="fa-solid fa-flask"></i> Hands-On Projects</strong></h3>
<h4 id="project-blueprint-policy-gradient-update-calculation"><strong>Project Blueprint: Policy Gradient Update Calculation</strong></h4>
<table>
<thead>
<tr>
<th style="text-align: left;">Component</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Objective</strong></td>
<td style="text-align: left;">Calculate the numerical parameter update for a single step of a quantum policy gradient algorithm.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Mathematical Concept</strong></td>
<td style="text-align: left;">The policy gradient update rule: $\Delta\theta = \alpha \cdot \nabla_\theta \log \pi_\theta(a</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Experiment Setup</strong></td>
<td style="text-align: left;">An agent takes an action with policy probability $\pi_\theta(a</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Process Steps</strong></td>
<td style="text-align: left;">1. Calculate the weighted gradient term: $\nabla_\theta J_{\text{weighted}} = \nabla_\theta \log \pi_\theta(a</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Expected Behavior</strong></td>
<td style="text-align: left;">The parameter <span class="arithmatex">\(\theta\)</span> should change in a positive direction, reinforcing the action that led to the positive return.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Verification Goal</strong></td>
<td style="text-align: left;">Quantify the exact change in the parameter <span class="arithmatex">\(\theta\)</span> for this single update step.</td>
</tr>
</tbody>
</table>
<h4 id="pseudocode-for-the-calculation"><strong>Pseudocode for the Calculation</strong></h4>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>FUNCTION Calculate_Policy_Gradient_Update(score_function, return_G, learning_rate_alpha):
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    // Step 1: Validate inputs
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    ASSERT Is_Numeric(score_function)
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    ASSERT Is_Numeric(return_G)
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    ASSERT learning_rate_alpha &gt; 0
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    LOG &quot;Inputs validated.&quot;
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    // Step 2: Calculate the weighted gradient (unscaled update direction)
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    // This term combines the direction (score) with the magnitude of success (return)
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    weighted_gradient = score_function * return_G
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    LOG &quot;Calculated Weighted Gradient: &quot; + weighted_gradient
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    // Step 3: Apply the learning rate to get the final parameter update
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    // This scales the update to control the step size
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    parameter_update = learning_rate_alpha * weighted_gradient
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    LOG &quot;Calculated Parameter Update (Delta Theta): &quot; + parameter_update
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    // Step 4: Return the calculated update value
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    RETURN parameter_update
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>END FUNCTION
</span></code></pre></div>
<h4 id="outcome-and-interpretation"><strong>Outcome and Interpretation</strong></h4>
<p>The weighted gradient is <span class="arithmatex">\(2.0 \times 5.0 = 10.0\)</span>. The parameter update is <span class="arithmatex">\(\Delta\theta = 0.1 \times 10.0 = 1.0\)</span>. This means the policy parameter <span class="arithmatex">\(\theta\)</span> would be increased by <span class="arithmatex">\(1.0\)</span>. This calculation demonstrates the core feedback loop of policy gradient methods: a positive outcome (<span class="arithmatex">\(G_t=5.0\)</span>) leads to a significant, positive adjustment to the policy parameters, making the preceding action more probable in the future.</p>
<hr />
<h2 class="heading-with-pill" id="133-quantum-value-iteration"><strong>13.3 Quantum Value Iteration</strong></h2>
<blockquote>
<p><strong>Difficulty:</strong> </p>
<p><strong>Concept:</strong> Value Function Approximation with PQCs</p>
<p><strong>Summary:</strong> Quantum Value Iteration methods use a PQC to approximate the action-value function, <span class="arithmatex">\(Q(s, a)\)</span>. The circuit is trained by minimizing the temporal-difference error, which measures the inconsistency between the current value estimate and a more accurate target value derived from the Bellman equation.</p>
</blockquote>
<hr />
<h3 id="theoretical-background_2"><strong>Theoretical Background</strong></h3>
<p>In contrast to policy gradient methods, value-based methods learn a <strong>value function</strong> first, and then derive a policy from it. The most common is the <strong>action-value function</strong>, <span class="arithmatex">\(Q(s, a)\)</span>, which represents the expected return from taking action <span class="arithmatex">\(a\)</span> in state <span class="arithmatex">\(s\)</span> and following the policy thereafter.</p>
<p>The optimal Q-function, <span class="arithmatex">\(Q^*(s, a)\)</span>, obeys the <strong>Bellman optimality equation</strong>:</p>
<div class="arithmatex">\[
Q^*(s, a) = \mathbb{E} \left[ r_{t+1} + \gamma \max_{a'} Q^*(s_{t+1}, a') \right]
\]</div>
<p>This equation states that the value of the current state-action pair is the immediate reward plus the discounted value of the best possible action in the next state.</p>
<p><strong>Quantum Value Iteration</strong> uses a PQC, denoted <span class="arithmatex">\(Q_\theta(s, a)\)</span>, to approximate this function. The training does not optimize for rewards directly, but instead tries to make the PQC satisfy the Bellman equation. This is done by minimizing the <strong>temporal-difference (TD) error</strong>. For a given transition <span class="arithmatex">\((s, a, r, s')\)</span>, the TD error is the difference between the current estimate and a more refined "target" estimate:</p>
<ul>
<li><strong>Current Estimate:</strong> <span class="arithmatex">\(Q_\theta(s, a)\)</span></li>
<li><strong>TD Target:</strong> <span class="arithmatex">\(r + \gamma \max_{a'} Q_\theta(s', a')\)</span></li>
</ul>
<p>The <strong>loss function</strong> is typically the mean squared error between these two quantities:</p>
<div class="arithmatex">\[
\mathcal{L}(\theta) = \left( \underbrace{r + \gamma \max_{a'} Q_\theta(s', a')}_{\text{TD Target}} - \underbrace{Q_\theta(s, a)}_{\text{Current Estimate}} \right)^2
\]</div>
<p>By minimizing this loss, the PQC <span class="arithmatex">\(Q_\theta(s, a)\)</span> is trained to become a self-consistent estimator of the true action-values.</p>
<hr />
<h3 id="comprehension-check_2"><strong>Comprehension Check</strong></h3>
<div class="admonition note">
<p class="admonition-title">Quiz</p>
<ol>
<li>In value-based QRL, what function is approximated by the PQC?</li>
<li>The loss function in Quantum Value Iteration aims to minimize what quantity?</li>
</ol>
<details class="info">
<summary>See Answer</summary>
<ol>
<li>The <strong>action-value function <span class="arithmatex">\(Q(s, a)\)</span></strong>.</li>
<li>The <strong>temporal-difference (TD) error</strong>, which is the squared difference between the current Q-value estimate and the TD target.</li>
</ol>
</details>
</div>
<div class="admonition abstract">
<p class="admonition-title">Interview-Style Question</p>
<p>What is the fundamental difference in what is being learned in a policy gradient method versus a value iteration method?</p>
<details class="info" open="open">
<summary>Answer Strategy</summary>
<p>The fundamental difference is what each method chooses to model and learn directly.</p>
<ol>
<li>
<p><strong>Policy Gradient (Direct Policy Learning):</strong></p>
<ul>
<li><strong>What it learns:</strong> The policy itself, <span class="arithmatex">\(\pi_\theta(a|s)\)</span>.</li>
<li><strong>How it works:</strong> It directly adjusts the parameters of the policy to favor actions that lead to higher rewards.</li>
<li><strong>It answers the question:</strong> "In this state, what is the best action to take?"</li>
</ul>
</li>
<li>
<p><strong>Value Iteration (Indirect Policy Learning):</strong></p>
<ul>
<li><strong>What it learns:</strong> The action-value function, <span class="arithmatex">\(Q(s, a)\)</span>.</li>
<li><strong>How it works:</strong> It learns the expected long-term reward (the "value") of taking any action in any state. The policy is then derived from these values (e.g., by always picking the action with the highest Q-value).</li>
<li><strong>It answers the question:</strong> "In this state, how good is it to take this action?"</li>
</ul>
</li>
</ol>
<p>In short, policy gradient methods learn a <strong>strategy</strong> directly, while value iteration methods learn a <strong>map of values</strong> and then derive the strategy from that map.</p>
</details>
</div>
<hr />
<h3 id="hands-on-projects_1"><strong><i class="fa-solid fa-flask"></i> Hands-On Projects</strong></h3>
<h4 id="project-blueprint-value-iteration-loss-calculation"><strong>Project Blueprint: Value Iteration Loss Calculation</strong></h4>
<table>
<thead>
<tr>
<th style="text-align: left;">Component</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Objective</strong></td>
<td style="text-align: left;">Calculate the Temporal Difference (TD) error and the corresponding loss for a single update step in a Q-learning-style algorithm.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Mathematical Concept</strong></td>
<td style="text-align: left;">The squared TD error loss function: <span class="arithmatex">\(\mathcal{L} = (\text{TD Target} - Q_\theta(s, a))^2\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Experiment Setup</strong></td>
<td style="text-align: left;">Discount factor <span class="arithmatex">\(\gamma = 0.9\)</span>; immediate reward <span class="arithmatex">\(r = 1.0\)</span>; current Q-value estimate <span class="arithmatex">\(Q_\theta(s, a) = 5.5\)</span>; best next-state Q-value estimate <span class="arithmatex">\(\max_{a'} Q_\theta(s', a') = 6.0\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Process Steps</strong></td>
<td style="text-align: left;">1. Calculate the TD Target: <span class="arithmatex">\(r + \gamma \max_{a'} Q_\theta(s', a')\)</span>. <br> 2. Calculate the TD Error: TD Target - <span class="arithmatex">\(Q_\theta(s, a)\)</span>. <br> 3. Calculate the squared TD error loss, <span class="arithmatex">\(\mathcal{L}\)</span>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Expected Behavior</strong></td>
<td style="text-align: left;">The loss will be a non-zero positive value, indicating an inconsistency in the current Q-function that the optimizer will seek to reduce.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Verification Goal</strong></td>
<td style="text-align: left;">Quantify the precise loss value that would be backpropagated to update the PQC parameters.</td>
</tr>
</tbody>
</table>
<h4 id="pseudocode-for-the-calculation_1"><strong>Pseudocode for the Calculation</strong></h4>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>FUNCTION Calculate_TD_Loss(current_Q_value, next_max_Q_value, reward, gamma):
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>    // Step 1: Validate inputs
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>    ASSERT Is_Numeric(current_Q_value) AND Is_Numeric(next_max_Q_value)
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>    ASSERT Is_Numeric(reward)
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>    ASSERT 0 &lt;= gamma &lt;= 1
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>    LOG &quot;Inputs validated.&quot;
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>    // Step 2: Calculate the TD Target based on the Bellman equation
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    // This is the &quot;better&quot; estimate of the Q-value we are trying to move towards
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    td_target = reward + (gamma * next_max_Q_value)
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    LOG &quot;Calculated TD Target: &quot; + td_target
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    // Step 3: Calculate the TD Error
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>    // This is the difference between the target and our current estimate
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    td_error = td_target - current_Q_value
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>    LOG &quot;Calculated TD Error: &quot; + td_error
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>    // Step 4: Calculate the squared TD error for the loss function
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>    // Squaring ensures the loss is always positive and penalizes larger errors more
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>    loss = td_error * td_error
</span><span id="__span-1-21"><a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>    LOG &quot;Calculated Loss (Squared TD Error): &quot; + loss
</span><span id="__span-1-22"><a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>
</span><span id="__span-1-23"><a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>    // Step 5: Return the final loss value
</span><span id="__span-1-24"><a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>    RETURN loss
</span><span id="__span-1-25"><a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>END FUNCTION
</span></code></pre></div>
<h4 id="outcome-and-interpretation_1"><strong>Outcome and Interpretation</strong></h4>
<p>The TD Target is <span class="arithmatex">\(1.0 + (0.9 \times 6.0) = 1.0 + 5.4 = 6.4\)</span>. The TD Error is <span class="arithmatex">\(6.4 - 5.5 = 0.9\)</span>. The final loss is <span class="arithmatex">\(\mathcal{L} = 0.9^2 = 0.81\)</span>. This loss value of <span class="arithmatex">\(0.81\)</span> represents the magnitude of the "Bellman error" for this transition. A classical optimizer would now compute the gradient of this loss with respect to the PQC parameters <span class="arithmatex">\(\theta\)</span> and update them to make the <code>current_Q</code> estimate of <span class="arithmatex">\(5.5\)</span> closer to the more accurate <code>td_target</code> of <span class="arithmatex">\(6.4\)</span>.</p>
<hr />
<h2 class="heading-with-pill" id="134-quantum-exploration-strategies"><strong>13.4 Quantum Exploration Strategies</strong></h2>
<blockquote>
<p><strong>Concept:</strong> Coherent State Space Search  <strong>Difficulty:</strong> </p>
<p><strong>Summary:</strong> QRL can leverage quantum phenomena like superposition and interference to create powerful, non-classical exploration strategies. Methods like quantum random walks allow for a more efficient and structured search of the environment, overcoming the limitations of simple random exploration used in classical RL.</p>
</blockquote>
<hr />
<h3 id="theoretical-background_3"><strong>Theoretical Background</strong></h3>
<p>A fundamental challenge in RL is the <strong>exploration-exploitation trade-off</strong>. An agent must exploit known high-reward actions but also explore the environment to discover potentially better strategies. Classical methods, like <strong><span class="arithmatex">\(\epsilon\)</span>-greedy</strong>, are simple: with probability <span class="arithmatex">\(1-\epsilon\)</span>, choose the best-known action; with probability <span class="arithmatex">\(\epsilon\)</span>, choose a random action. This is a purely probabilistic and "memoryless" form of exploration.</p>
<p>QRL opens the door to <strong>coherent exploration</strong> strategies.</p>
<ol>
<li>
<p><strong>Quantum Random Walks:</strong> Instead of a classical random walk where the agent hops from state to state probabilistically, a <strong>quantum random walk</strong> evolves a superposition of states. The "walker" (agent) can traverse multiple paths simultaneously. Interference effects can then be used to suppress paths leading to low-reward regions and amplify paths leading to high-reward regions. This allows for a much faster and more directed search of large state spaces.</p>
</li>
<li>
<p><strong>Amplitude Amplification:</strong> This is the core mechanism behind Grover's algorithm. In QRL, it can be adapted to modify the agent's policy. If a certain action leads to a high reward, amplitude amplification can be used to increase the probability amplitude of that action in the policy state, making it more likely to be chosen in the future. This provides a quadratic speedup in finding high-reward actions compared to classical random search.</p>
</li>
</ol>
<p>These quantum strategies move beyond simple randomness, introducing a structured, wave-like search that can be significantly more efficient.</p>
<hr />
<h3 id="comprehension-check_3"><strong>Comprehension Check</strong></h3>
<div class="admonition note">
<p class="admonition-title">Quiz</p>
<ol>
<li>What is the name for the RL dilemma of choosing between known good actions and trying new ones?</li>
<li>How does a quantum random walk differ from a classical one?</li>
</ol>
<details class="info">
<summary>See Answer</summary>
<ol>
<li>The <strong>exploration-exploitation trade-off</strong>.</li>
<li>A quantum random walk evolves a <strong>superposition</strong> of states, allowing it to explore many paths at once and use <strong>interference</strong> to amplify promising directions. A classical random walk follows a single, probabilistic path.</li>
</ol>
</details>
</div>
<div class="admonition abstract">
<p class="admonition-title">Interview-Style Question</p>
<p>Explain what "coherent exploration" means and why it's fundamentally different from <span class="arithmatex">\(\epsilon\)</span>-greedy exploration.</p>
<details class="info" open="open">
<summary>Answer Strategy</summary>
<p>The difference is between a random, memoryless search and a structured, parallel search.</p>
<ol>
<li>
<p><strong>Classical <span class="arithmatex">\(\epsilon\)</span>-greedy (Incoherent Search):</strong> This is a purely probabilistic strategy. The decision to explore is like an independent coin flip at each step. There is no memory or structure to the exploration; the agent simply "jumps" to a random action. It's a memoryless, point-by-point search.</p>
</li>
<li>
<p><strong>Quantum Coherent Exploration (Wave-like Search):</strong> This strategy uses quantum superposition to explore many possible paths simultaneously. The agent's state is a wave that evolves through the state space. The different paths maintain phase relationships and can interfere with each other.</p>
<ul>
<li><strong>Constructive Interference:</strong> Amplifies paths leading to high-reward regions.</li>
<li><strong>Destructive Interference:</strong> Cancels out paths leading to low-reward regions.</li>
</ul>
</li>
</ol>
<p><strong>Analogy:</strong> <span class="arithmatex">\(\epsilon\)</span>-greedy is like a person in a maze randomly trying one door at a time. Coherent exploration is like a flood of water that spreads through the entire maze at once, with the flow naturally concentrating towards the exit. It's a deterministic, highly parallel, and structured search.</p>
</details>
</div>
<hr />
<h2 class="heading-with-pill" id="135-quantum-agent-architectures"><strong>13.5 Quantum Agent Architectures</strong></h2>
<blockquote>
<p><strong>Concept:</strong> Hybrid Quantum-Classical Agent Design  <strong>Difficulty:</strong> </p>
<p><strong>Summary:</strong> A QRL agent is a hybrid system where quantum and classical components work in tandem. The PQC acts as the "brain" for policy or value estimation, while classical processors manage the optimization loop, memory, and interaction with the environment, which itself can be classical or quantum.</p>
</blockquote>
<hr />
<h3 id="theoretical-background_4"><strong>Theoretical Background</strong></h3>
<p>A practical QRL agent is not a monolithic quantum computer but a <strong>hybrid quantum-classical architecture</strong>. The components are divided based on what they do best.</p>
<ul>
<li><strong>Policy/Value Function (Quantum):</strong> This is the core quantum component, typically a PQC. Its ability to handle high-dimensional spaces is leveraged here.</li>
<li><strong>Action Selection (Quantum/Classical):</strong> An action is chosen by <strong>sampling</strong> from the output of the policy PQC. This involves a quantum measurement followed by a classical decision.</li>
<li><strong>Learning/Optimization (Classical):</strong> The gradients of the loss function are calculated (often with quantum assistance, like the parameter-shift rule), but the actual parameter update step (<span class="arithmatex">\(\theta \leftarrow \theta - \alpha \nabla J(\theta)\)</span>) is performed by a classical optimizer (e.g., Adam, SGD).</li>
<li><strong>Memory (Classical/Quantum):</strong> In simple agents, memory (like storing past transitions for experience replay) is classical. In more advanced future architectures, <strong>Quantum Random Access Memory (QRAM)</strong> could be used to store and retrieve quantum states from a superposition of addresses, enabling powerful new memory-based strategies.</li>
<li><strong>Environment (Classical/Quantum):</strong> The agent can interact with a classical simulated environment (like a video game), a simulated quantum environment, or even a <strong>real physical quantum system</strong>.</li>
</ul>
<p>This final case, where the environment is a real quantum experiment, is a particularly exciting application. The QRL agent can learn to become an "autonomous physicist," optimizing experimental parameters (e.g., laser pulse shapes, magnetic field strengths) to achieve a desired outcome (e.g., creating a specific entangled state) more effectively than human researchers.</p>
<hr />
<h3 id="comprehension-check_4"><strong>Comprehension Check</strong></h3>
<div class="admonition note">
<p class="admonition-title">Quiz</p>
<ol>
<li>In a hybrid QRL agent, which component is typically handled by a classical optimizer like Adam?</li>
<li>What futuristic quantum technology is proposed for advanced agent memory?</li>
</ol>
<details class="info">
<summary>See Answer</summary>
<ol>
<li>The <strong>learning/optimization</strong> step (i.e., updating the parameters <span class="arithmatex">\(\theta\)</span>).</li>
<li><strong>Quantum Random Access Memory (QRAM)</strong>.</li>
</ol>
</details>
</div>
<div class="admonition abstract">
<p class="admonition-title">Interview-Style Question</p>
<p>Describe a scenario where the "environment" in a QRL setup is itself a quantum system. What are the state, action, and reward?</p>
<details class="info" open="open">
<summary>Answer Strategy</summary>
<p>This describes a powerful application where a QRL agent acts as an "autonomous physicist," learning to control a quantum experiment.</p>
<ul>
<li>
<p><strong>Scenario:</strong> An agent is tasked with creating a high-fidelity three-qubit GHZ state in a trapped-ion experiment.</p>
</li>
<li>
<p><strong>State (<span class="arithmatex">\(s_t\)</span>):</strong> The state is a classical description of the outcome of the previous attempt. This could be a vector containing the measured populations of the 8 basis states (e.g., <span class="arithmatex">\(|000\rangle, |001\rangle, \dots\)</span>) and the coherences between them, obtained via quantum state tomography.</p>
</li>
<li>
<p><strong>Action (<span class="arithmatex">\(a_t\)</span>):</strong> The action is a set of classical control parameters for the experimental apparatus. For instance, it could be a vector specifying the duration, intensity, and frequency of the laser pulses applied to the ions.</p>
</li>
<li>
<p><strong>Reward (<span class="arithmatex">\(r_{t+1}\)</span>):</strong> The reward is a single number quantifying the success of the experiment. The most direct reward is the <strong>fidelity</strong> of the created state <span class="arithmatex">\(|\psi_{\text{actual}}\rangle\)</span> with respect to the ideal GHZ state <span class="arithmatex">\(|\psi_{\text{GHZ}}\rangle\)</span>:
    $$
    r_{t+1} = F = |\langle \psi_{\text{GHZ}} | \psi_{\text{actual}} \rangle|^2
    $$
    The agent's goal is to learn the sequence of actions (laser pulses) that maximizes this fidelity, thereby discovering the optimal control protocol for the experiment.</p>
</li>
</ul>
</details>
</div>









  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../../chapter-12/Chapter-12-Workbook/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Chapter-12 Unsupervised Quantum Machine Learning">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Chapter-12 Unsupervised Quantum Machine Learning
              </div>
            </div>
          </a>
        
        
          
          <a href="../../chapter-14/Chapter-14-Workbook/" class="md-footer__link md-footer__link--next" aria-label="Next: Chapter-14 QUBO Family of Problems">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Chapter-14 QUBO Family of Problems
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://bigbookofcomputing.github.io" target="_blank" rel="noopener" title="bigbookofcomputing.github.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://x.com/bigbookofcomputing" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.facebook.com/bigbookofcomputing" target="_blank" rel="noopener" title="www.facebook.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256c0 120 82.7 220.8 194.2 248.5V334.2h-52.8V256h52.8v-33.7c0-87.1 39.4-127.5 125-127.5 16.2 0 44.2 3.2 55.7 6.4V172c-6-.6-16.5-1-29.6-1-42 0-58.2 15.9-58.2 57.2V256h83.6l-14.4 78.2H287v175.9C413.8 494.8 512 386.9 512 256"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/bigbookofcomputing" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/@big-book-of-computing" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            


  


<h4>Cookie consent</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
    
      
        
  
  
    
    
  
  <li class="task-list-item">
    <label class="task-list-control">
      <input type="checkbox" name="analytics" checked>
      <span class="task-list-indicator"></span>
      Google Analytics
    </label>
  </li>

      
    
    
      
        
  
  
    
    
  
  <li class="task-list-item">
    <label class="task-list-control">
      <input type="checkbox" name="github" checked>
      <span class="task-list-indicator"></span>
      GitHub
    </label>
  </li>

      
    
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">Accept</button>
    
    
    
  
    
    
    
      <label class="md-button" for="__settings">Manage settings</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script>
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../static/mathjax-config.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>